{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks Project - Credit Risks Analysis\n",
    "\n",
    "An experimental study about a neural network model aplication in a real world problem.\n",
    "\n",
    "Neural Networks - Minister by Germano Vasconcelos\n",
    "\n",
    "Team:  \n",
    "- Lucas Alves Rufno  \n",
    "- Rodrigo de Lima Oliveira  \n",
    "- Ullayne Fernandes Farias de Lima \n",
    "- Vitor Jose da Silva Lima\n",
    "\n",
    "## Emseble of Multilayer Perceptron \n",
    "\n",
    "Serie of experiments to evaluate the credit risks analysis using a statistical model\n",
    "\n",
    "### Imports:\n",
    "Relevant libraries to solve the problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from scipy.stats import ks_2samp as ksTest\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read dataset:\n",
    "Read file as .h5 in Pandas with respective keys and describe data partially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tr = pd.read_hdf(\"datasets/repeat/Train.h5\", key='train')\n",
    "va = pd.read_hdf(\"datasets/repeat/Validation.h5\", key='validation')\n",
    "te = pd.read_hdf(\"datasets/repeat/Test.h5\", key='test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modify dataset:\n",
    "Modifying the dataset to only 2 sets (Train and Test). The validation set is splitter in the algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tr = tr.append(va)\n",
    "tr = shuffle(tr)\n",
    "tr1 = tr.iloc[:,:-1]\n",
    "tr2 = tr['IND_BOM_1_1']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trainning model:\n",
    "Define a module to put on emseble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mlp1():\n",
    "        clf = MLPClassifier(\n",
    "        hidden_layer_sizes=(1000,),\n",
    "        solver='sgd',\n",
    "        activation='relu',\n",
    "        learning_rate='constant',\n",
    "        learning_rate_init=0.03,\n",
    "        early_stopping=True,\n",
    "        validation_fraction=0.1)\n",
    "        clf.fit(tr1, tr2)\n",
    "        #rClass = clf.predict(te.iloc[:,:-1])\n",
    "        #rProba = clf.predict_proba(te.iloc[:,:-1])[:,1]\n",
    "        return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mlp2():\n",
    "        clf = MLPClassifier(\n",
    "        hidden_layer_sizes=(200,),\n",
    "        solver='sgd',\n",
    "        activation='relu',\n",
    "        learning_rate='constant',\n",
    "        learning_rate_init=0.03,\n",
    "        early_stopping=True,\n",
    "        validation_fraction=0.1)\n",
    "        clf.n_layers_ = 2\n",
    "        clf.fit(tr1, tr2)\n",
    "        #rClass = clf.predict(te.iloc[:,:-1])\n",
    "        #rProba = clf.predict_proba(te.iloc[:,:-1])[:,1]\n",
    "        return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mlp3(): \n",
    "    clf = MLPClassifier(\n",
    "    hidden_layer_sizes=(200,),\n",
    "    solver='sgd',\n",
    "    activation='relu',\n",
    "    learning_rate='constant',\n",
    "    learning_rate_init=0.03,\n",
    "    early_stopping=True,\n",
    "    validation_fraction=0.1)\n",
    "    clf.n_layers_ = 3\n",
    "    clf.fit(tr1, tr2)\n",
    "    #rClass = clf.predict(te.iloc[:,:-1])\n",
    "    #rProba = clf.predict_proba(te.iloc[:,:-1])[:,1]\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def med(rProba, rClass): \n",
    "    print('MSE:', metrics.mean_squared_error(te['IND_BOM_1_1'], rProba))\n",
    "    print('KS Test:', ksTest(te['IND_BOM_1_1'], rProba)[0])\n",
    "    print('ROC AUC:', metrics.roc_auc_score(te['IND_BOM_1_1'], rProba))\n",
    "    print('Accuracy:', metrics.accuracy_score(te['IND_BOM_1_1'], rClass))\n",
    "    print('Precision, Recall and FScore:')\n",
    "    print(metrics.precision_recall_fscore_support(te['IND_BOM_1_1'], rClass, average='binary')[:-1])\n",
    "    print('Confusion Matrix:')\n",
    "    print(metrics.confusion_matrix(te['IND_BOM_1_1'], rClass))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.239506804947\n",
      "KS Test: 0.655450266193\n",
      "ROC AUC: 0.659434939662\n",
      "Accuracy: 0.611872803141\n",
      "Precision, Recall and FScore:\n",
      "(0.75212283354658604, 0.60833568538903005, 0.67263081244148548)\n",
      "Confusion Matrix:\n",
      "[[20738 12786]\n",
      " [24978 38796]]\n"
     ]
    }
   ],
   "source": [
    "clf1 = mlp1()\n",
    "rClass = clf1.predict(te.iloc[:,:-1])\n",
    "rProba = clf1.predict_proba(te.iloc[:,:-1])[:,1]\n",
    "med(rProba,rClass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.231676943954\n",
      "KS Test: 0.655450266193\n",
      "ROC AUC: 0.688034434567\n",
      "Accuracy: 0.611564472034\n",
      "Precision, Recall and FScore:\n",
      "(0.786716991127003, 0.55889547464483957, 0.65352035203520353)\n",
      "Confusion Matrix:\n",
      "[[23861  9663]\n",
      " [28131 35643]]\n"
     ]
    }
   ],
   "source": [
    "clf2 = mlp2()\n",
    "rClass = clf2.predict(te.iloc[:,:-1])\n",
    "rProba = clf2.predict_proba(te.iloc[:,:-1])[:,1]\n",
    "med(rProba,rClass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.222655225127\n",
      "KS Test: 0.655450266193\n",
      "ROC AUC: 0.689289324524\n",
      "Accuracy: 0.630763222266\n",
      "Precision, Recall and FScore:\n",
      "(0.77316958330063568, 0.61796343337410231, 0.68690847611245709)\n",
      "Confusion Matrix:\n",
      "[[21962 11562]\n",
      " [24364 39410]]\n"
     ]
    }
   ],
   "source": [
    "clf3 = mlp3()\n",
    "rClass = clf3.predict(te.iloc[:,:-1])\n",
    "rProba = clf3.predict_proba(te.iloc[:,:-1])[:,1]\n",
    "med(rProba,rClass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'VotingClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-9e86267a42a3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0meclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVotingClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'mlp1'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclf1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'mlp2'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclf2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'mlp3'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclf3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvoting\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'soft'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0meclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0meclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtr1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtr2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mrClass\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0meclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mte\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mrProba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0meclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mte\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrProba\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrClass\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'VotingClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "eclf = VotingClassifier(estimators=[('mlp1', clf1),('mlp2', clf2),('mlp3', clf3)], voting='soft')\n",
    "eclf = eclf.fit(tr1,tr2)\n",
    "rClass = eclf.predict(te.iloc[:,:-1])\n",
    "rProba = eclf.predict_proba(te.iloc[:,:-1])[:,1]\n",
    "med(rProba,rClass)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating model:\n",
    "Testing the statistical model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.22201866924001076\n",
      "KS Test: 0.6554502661925219\n",
      "ROC AUC: 0.6789338906564995\n",
      "Accuracy: 0.6346481942074863\n",
      "Precision, Recall and FScore:\n",
      "(0.7577152039735583, 0.6506413271866278, 0.7001079840723494)\n",
      "Confusion Matrix:\n",
      "[[20256 13268]\n",
      " [22280 41494]]\n"
     ]
    }
   ],
   "source": [
    "print('MSE:', metrics.mean_squared_error(te['IND_BOM_1_1'], rProba))\n",
    "print('KS Test:', ksTest(te['IND_BOM_1_1'], rProba)[0])\n",
    "print('ROC AUC:', metrics.roc_auc_score(te['IND_BOM_1_1'], rProba))\n",
    "print('Accuracy:', metrics.accuracy_score(te['IND_BOM_1_1'], rClass))\n",
    "print('Precision, Recall and FScore:')\n",
    "print(metrics.precision_recall_fscore_support(te['IND_BOM_1_1'], rClass, average='binary')[:-1])\n",
    "print('Confusion Matrix:')\n",
    "print(metrics.confusion_matrix(te['IND_BOM_1_1'], rClass))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
